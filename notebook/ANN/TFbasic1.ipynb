{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow 2.0\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용 함수\n",
    "from tensorflow.keras.layers import Dense       # class\n",
    "\n",
    "# tensorflow 1.x\n",
    "# from keras.models import Sequential  # class\n",
    "# from keras.models import load_model  # model 사용 함수\n",
    "# from keras.layers import Dense       # class\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 24ms/sample - loss: 829.7185 - val_loss: 3035.9805\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 822.7386 - val_loss: 3008.6976\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 814.7217 - val_loss: 2983.8841\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 807.9467 - val_loss: 2956.3325\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 800.3415 - val_loss: 2930.9786\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 793.5430 - val_loss: 2904.3400\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 785.8028 - val_loss: 2880.4568\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 778.8695 - val_loss: 2855.5789\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 771.7021 - val_loss: 2831.2441\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 764.5427 - val_loss: 2807.3564\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 757.5699 - val_loss: 2783.3890\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 751.1131 - val_loss: 2756.3862\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 744.0140 - val_loss: 2731.0054\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 736.9175 - val_loss: 2707.1210\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 729.9004 - val_loss: 2684.6045\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 723.2166 - val_loss: 2661.5393\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 716.6884 - val_loss: 2637.4004\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 710.1280 - val_loss: 2612.8058\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 703.1655 - val_loss: 2590.3746\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 697.2305 - val_loss: 2564.6541\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 690.6436 - val_loss: 2540.0380\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 683.6619 - val_loss: 2517.9918\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 677.3782 - val_loss: 2495.2101\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 671.0048 - val_loss: 2472.7042\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 664.4719 - val_loss: 2451.3415\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 658.2597 - val_loss: 2429.7416\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 651.9410 - val_loss: 2408.5260\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 645.8766 - val_loss: 2386.3274\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 639.7738 - val_loss: 2363.9696\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 633.5861 - val_loss: 2342.0147\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 627.2658 - val_loss: 2321.7926\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 621.7050 - val_loss: 2298.7227\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 615.2659 - val_loss: 2278.3771\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 609.7608 - val_loss: 2255.8040\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 603.2968 - val_loss: 2236.1483\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 597.5244 - val_loss: 2216.0506\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 592.3559 - val_loss: 2192.9441\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 585.7532 - val_loss: 2173.9417\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 580.6484 - val_loss: 2151.9529\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 574.5593 - val_loss: 2132.0165\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 568.6143 - val_loss: 2113.8225\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 563.5122 - val_loss: 2092.7530\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 557.6414 - val_loss: 2073.3557\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 552.1642 - val_loss: 2053.7353\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 546.6283 - val_loss: 2034.3972\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 541.1585 - val_loss: 2015.3427\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 536.0124 - val_loss: 1995.0313\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 530.0650 - val_loss: 1978.3144\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 525.1915 - val_loss: 1958.1567\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 519.8967 - val_loss: 1938.1690\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 514.3413 - val_loss: 1919.9335\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 509.1333 - val_loss: 1901.7835\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 503.8999 - val_loss: 1883.8633\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 499.2876 - val_loss: 1863.4380\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 493.5008 - val_loss: 1846.8468\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 489.1440 - val_loss: 1826.4155\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 483.3869 - val_loss: 1809.9454\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 478.6632 - val_loss: 1791.7739\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 473.6253 - val_loss: 1774.1974\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 468.6171 - val_loss: 1757.1456\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 463.9849 - val_loss: 1738.7856\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 458.7896 - val_loss: 1722.5325\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 454.4216 - val_loss: 1703.9271\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 449.1666 - val_loss: 1688.0800\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 444.7612 - val_loss: 1670.4694\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 439.7031 - val_loss: 1655.0024\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 435.4479 - val_loss: 1637.1906\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 430.6273 - val_loss: 1620.5090\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 425.8170 - val_loss: 1605.2341\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 421.6160 - val_loss: 1587.8372\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 416.8271 - val_loss: 1572.0584\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 412.7356 - val_loss: 1554.3982\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 407.8358 - val_loss: 1539.0154\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 403.5861 - val_loss: 1522.9902\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 399.3242 - val_loss: 1506.4893\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 394.5803 - val_loss: 1491.9639\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 390.3626 - val_loss: 1477.0164\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 386.0870 - val_loss: 1462.1246\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 382.0237 - val_loss: 1446.2236\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 377.6952 - val_loss: 1431.1182\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 373.7035 - val_loss: 1415.1209\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 369.4403 - val_loss: 1399.8822\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 365.0555 - val_loss: 1386.0969\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 361.0253 - val_loss: 1372.1121\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 357.0578 - val_loss: 1357.7466\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 353.4561 - val_loss: 1341.4338\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 348.7281 - val_loss: 1329.4075\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 345.2014 - val_loss: 1314.6171\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 341.0967 - val_loss: 1300.9453\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 337.2119 - val_loss: 1287.3801\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 333.5438 - val_loss: 1272.6321\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 329.5518 - val_loss: 1258.8051\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 325.8082 - val_loss: 1244.7749\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 322.1503 - val_loss: 1230.3299\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 318.1704 - val_loss: 1217.2875\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 314.5484 - val_loss: 1203.8925\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 310.8972 - val_loss: 1190.5862\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 307.1955 - val_loss: 1177.5635\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 303.5862 - val_loss: 1164.8810\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 300.0718 - val_loss: 1151.5382\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 296.3041 - val_loss: 1139.8048\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 292.9689 - val_loss: 1126.7442\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 289.6884 - val_loss: 1112.6610\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 286.0441 - val_loss: 1099.6718\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 282.2719 - val_loss: 1088.9947\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 279.1535 - val_loss: 1076.3582\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 275.7889 - val_loss: 1063.7660\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 272.3617 - val_loss: 1051.6783\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 269.0804 - val_loss: 1039.5834\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 265.6778 - val_loss: 1028.2301\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 262.5829 - val_loss: 1015.8154\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 259.2505 - val_loss: 1004.1188\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 255.9635 - val_loss: 993.0427\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 252.9475 - val_loss: 981.0151\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 249.8246 - val_loss: 968.9139\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 246.5867 - val_loss: 957.5760\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 243.4600 - val_loss: 946.5330\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 240.7084 - val_loss: 934.1547\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 237.2630 - val_loss: 923.7758\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 234.5495 - val_loss: 912.1794\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 231.3046 - val_loss: 901.8790\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 228.5221 - val_loss: 890.7367\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 225.4039 - val_loss: 880.7061\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 222.6433 - val_loss: 869.9194\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 219.6335 - val_loss: 860.0486\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 216.8318 - val_loss: 849.9944\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 214.2697 - val_loss: 838.5600\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 211.1642 - val_loss: 828.8098\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 208.4018 - val_loss: 819.1189\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 205.7628 - val_loss: 808.8243\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 203.0219 - val_loss: 798.7189\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 200.4091 - val_loss: 788.2911\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 197.5397 - val_loss: 779.0587\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 194.9841 - val_loss: 769.3488\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 192.3405 - val_loss: 759.8834\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 189.7924 - val_loss: 750.1867\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 187.3400 - val_loss: 740.0387\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 184.6433 - val_loss: 730.7582\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 182.0302 - val_loss: 722.1117\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 179.6804 - val_loss: 712.6787\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 177.1775 - val_loss: 703.4571\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 174.7471 - val_loss: 694.2633\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 172.2654 - val_loss: 685.4504\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 169.9610 - val_loss: 676.2357\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 167.4838 - val_loss: 667.6390\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 165.1556 - val_loss: 659.0788\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 162.9461 - val_loss: 650.0422\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 160.3499 - val_loss: 642.8238\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 158.3995 - val_loss: 633.5211\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 155.9397 - val_loss: 625.4636\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 153.7028 - val_loss: 617.4517\n",
      "Epoch 152/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 151.5545 - val_loss: 609.1244\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 149.4651 - val_loss: 600.3769\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 147.1354 - val_loss: 592.5488\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 145.1182 - val_loss: 584.2205\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 142.9220 - val_loss: 576.2409\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 140.6939 - val_loss: 569.1119\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 138.8345 - val_loss: 560.7796\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 136.6597 - val_loss: 553.1905\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 134.7301 - val_loss: 545.2342\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 132.6020 - val_loss: 537.9270\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 130.6286 - val_loss: 530.5426\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 128.5950 - val_loss: 523.5799\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 126.7718 - val_loss: 515.9738\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 124.8672 - val_loss: 508.3989\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 122.9724 - val_loss: 500.9633\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 120.8929 - val_loss: 494.6388\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 119.2781 - val_loss: 487.0972\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 117.1904 - val_loss: 480.8198\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 115.4654 - val_loss: 474.0986\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 113.6381 - val_loss: 467.5060\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 111.9373 - val_loss: 460.5089\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 110.0635 - val_loss: 454.2336\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 108.3527 - val_loss: 447.8455\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 106.7439 - val_loss: 440.8599\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 104.9238 - val_loss: 434.6364\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 103.3111 - val_loss: 427.9992\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 101.6542 - val_loss: 421.4810\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 99.8920 - val_loss: 415.6879\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 98.3951 - val_loss: 409.2140\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 96.7385 - val_loss: 403.0725\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 95.1943 - val_loss: 396.8270\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 93.5190 - val_loss: 391.2855\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 92.1572 - val_loss: 384.8415\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 90.5445 - val_loss: 378.9814\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 88.9153 - val_loss: 373.6663\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 87.4278 - val_loss: 368.4796\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 86.1107 - val_loss: 362.3709\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 84.5486 - val_loss: 356.9481\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 83.1259 - val_loss: 351.4717\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 81.7557 - val_loss: 345.7949\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 80.2500 - val_loss: 340.7845\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 78.9418 - val_loss: 335.3784\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 77.5893 - val_loss: 329.9423\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 76.2072 - val_loss: 324.7515\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 74.8417 - val_loss: 319.9123\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 73.5892 - val_loss: 314.6394\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 72.3233 - val_loss: 309.2856\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 71.0159 - val_loss: 304.1911\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 69.6335 - val_loss: 299.8638\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 68.6065 - val_loss: 294.3944\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 67.1571 - val_loss: 290.1339\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 66.0300 - val_loss: 285.3985\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 64.8518 - val_loss: 280.5913\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 63.6108 - val_loss: 276.3197\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 62.5096 - val_loss: 271.5738\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 61.2906 - val_loss: 267.3377\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 60.1490 - val_loss: 263.3361\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 59.1230 - val_loss: 258.6197\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 58.0357 - val_loss: 253.9166\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 56.9239 - val_loss: 249.4633\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 55.7755 - val_loss: 245.4873\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 54.7731 - val_loss: 241.2434\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 53.7166 - val_loss: 237.1409\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 52.6635 - val_loss: 233.2807\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 51.7112 - val_loss: 229.1046\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 50.6745 - val_loss: 225.2309\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 49.6977 - val_loss: 221.3851\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 48.7651 - val_loss: 217.4006\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 47.7313 - val_loss: 213.9670\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 46.8895 - val_loss: 209.9314\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 45.9219 - val_loss: 206.2086\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 45.0066 - val_loss: 202.5824\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 44.1338 - val_loss: 198.8681\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 43.2071 - val_loss: 195.4664\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 42.3258 - val_loss: 192.3048\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 41.5376 - val_loss: 188.6394\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 40.6632 - val_loss: 185.2201\n",
      "Epoch 229/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 39.8317 - val_loss: 181.8699\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 39.0075 - val_loss: 178.6669\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 38.2297 - val_loss: 175.3165\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 37.4179 - val_loss: 172.1547\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 36.6365 - val_loss: 169.0475\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 35.9145 - val_loss: 165.7320\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 35.0985 - val_loss: 162.8987\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 34.4359 - val_loss: 159.6041\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 33.6536 - val_loss: 156.6630\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 32.9552 - val_loss: 153.6828\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 32.2202 - val_loss: 150.9254\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 31.5854 - val_loss: 147.8871\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 30.8822 - val_loss: 145.0317\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 30.1982 - val_loss: 142.3447\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 29.5142 - val_loss: 139.8791\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 28.9141 - val_loss: 137.1376\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 28.2744 - val_loss: 134.4808\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 27.6474 - val_loss: 131.8997\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 27.0624 - val_loss: 129.2003\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 26.4187 - val_loss: 126.8432\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 25.8580 - val_loss: 124.3184\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 25.2766 - val_loss: 121.8551\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 24.7046 - val_loss: 119.4685\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 24.1905 - val_loss: 116.8736\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 23.5947 - val_loss: 114.5874\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 23.0237 - val_loss: 112.6176\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 22.5284 - val_loss: 110.5059\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 22.0640 - val_loss: 108.0202\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 21.5560 - val_loss: 105.6583\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 20.9712 - val_loss: 103.9058\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 20.5431 - val_loss: 101.7157\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 20.1101 - val_loss: 99.3527\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 19.5652 - val_loss: 97.4344\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 19.1083 - val_loss: 95.5549\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 18.6647 - val_loss: 93.7143\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 18.2284 - val_loss: 91.8371\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 17.8022 - val_loss: 89.9463\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 17.3936 - val_loss: 87.9750\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 16.9499 - val_loss: 86.2563\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 16.5914 - val_loss: 84.2271\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 16.1612 - val_loss: 82.4543\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.7757 - val_loss: 80.6942\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.3819 - val_loss: 79.0940\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.0295 - val_loss: 77.3496\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 14.6951 - val_loss: 75.5035\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 14.2865 - val_loss: 73.9630\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 13.9397 - val_loss: 72.4819\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 13.5880 - val_loss: 71.1371\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 13.3076 - val_loss: 69.3975\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.9420 - val_loss: 67.9575\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.6440 - val_loss: 66.4059\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.3196 - val_loss: 64.9624\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.0125 - val_loss: 63.6024\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 11.7088 - val_loss: 62.2937\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 11.4205 - val_loss: 60.9964\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 11.1768 - val_loss: 59.4693\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.8436 - val_loss: 58.4021\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.6072 - val_loss: 57.0409\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.3518 - val_loss: 55.6765\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.0594 - val_loss: 54.6452\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.8463 - val_loss: 53.2760\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.5979 - val_loss: 51.9872\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.3222 - val_loss: 51.0360\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.1275 - val_loss: 49.7687\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.8769 - val_loss: 48.6902\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.6518 - val_loss: 47.6892\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.4870 - val_loss: 46.3936\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.2285 - val_loss: 45.3943\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.0168 - val_loss: 44.5273\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.8455 - val_loss: 43.4104\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.6365 - val_loss: 42.4265\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.4413 - val_loss: 41.5229\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15,16,17,18,19,20])\n",
    "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model2 = Sequential()\n",
    "\n",
    "# Single-Layer Perceptron\n",
    "# output node: 1\n",
    "# num of input: 1\n",
    "# activation function: linear\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "model2.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Setting Model\n",
    "# back propagation: adam\n",
    "# loss algorithm: mse\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Start Learning \n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True, epochs=300, batch_size=1)\n",
    "# x_train: data\n",
    "# y_train: target \n",
    "# validation_split=0.2: (0.8 => learning data, 0.2=> validation data)\n",
    "# shuffle=True (use randomized validation)\n",
    "# epochs=300 \n",
    "# batch_size=1 (update when 1 data learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 18ms/sample - loss: 142.0316 - val_loss: 516.1648\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 1ms/sample - loss: 139.0449 - val_loss: 505.0619\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 3ms/sample - loss: 135.8074 - val_loss: 495.1793\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 132.9438 - val_loss: 484.7445\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 130.0423 - val_loss: 474.3549\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 127.1133 - val_loss: 464.2954\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 124.5038 - val_loss: 453.5021\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 121.4552 - val_loss: 444.1855\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 118.9279 - val_loss: 434.2949\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 115.9968 - val_loss: 425.6910\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 113.3880 - val_loss: 417.0268\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 111.0180 - val_loss: 407.1212\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 108.2315 - val_loss: 398.8406\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 106.0097 - val_loss: 388.9726\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 103.3038 - val_loss: 380.6520\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 100.9822 - val_loss: 371.8430\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 98.4820 - val_loss: 363.9425\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 96.3443 - val_loss: 355.0835\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 93.9623 - val_loss: 346.9351\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 91.6642 - val_loss: 339.2791\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 89.4897 - val_loss: 331.5567\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 87.4512 - val_loss: 323.3460\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 85.1340 - val_loss: 316.2687\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 83.2107 - val_loss: 308.4699\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 81.0302 - val_loss: 301.5405\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 79.0478 - val_loss: 294.5752\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 77.1534 - val_loss: 287.3044\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 75.2014 - val_loss: 280.2843\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 73.2063 - val_loss: 274.0021\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 71.5009 - val_loss: 267.0623\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 69.5881 - val_loss: 260.6952\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 67.7434 - val_loss: 254.7953\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 66.0671 - val_loss: 248.5296\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 64.3978 - val_loss: 242.0941\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 62.6347 - val_loss: 236.2193\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 60.9529 - val_loss: 230.7315\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 59.4689 - val_loss: 224.5298\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 57.7809 - val_loss: 219.0663\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 56.3098 - val_loss: 213.2031\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 54.8411 - val_loss: 207.2934\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 53.1764 - val_loss: 202.4240\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 51.7455 - val_loss: 197.5646\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 50.3844 - val_loss: 192.3981\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 48.9798 - val_loss: 187.4513\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 47.6799 - val_loss: 182.2118\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 46.2678 - val_loss: 177.4656\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 44.9709 - val_loss: 172.8673\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 43.7818 - val_loss: 167.8141\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 42.4201 - val_loss: 163.4918\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 41.2526 - val_loss: 158.9599\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 39.9938 - val_loss: 154.9330\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 38.8546 - val_loss: 150.8334\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 37.7666 - val_loss: 146.5128\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 36.6099 - val_loss: 142.5305\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 35.5104 - val_loss: 138.6869\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 34.5566 - val_loss: 134.3689\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 33.4282 - val_loss: 130.5991\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 32.3781 - val_loss: 127.1321\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 31.4893 - val_loss: 123.2299\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 30.4346 - val_loss: 119.8862\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 29.5759 - val_loss: 116.1996\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 28.5810 - val_loss: 112.9951\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 27.7042 - val_loss: 109.7774\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 26.8314 - val_loss: 106.6084\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 25.9743 - val_loss: 103.5586\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 25.1344 - val_loss: 100.7315\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 24.3533 - val_loss: 97.7158\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 23.6054 - val_loss: 94.5211\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 22.7818 - val_loss: 91.7206\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 22.0632 - val_loss: 88.8305\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 21.2844 - val_loss: 86.3449\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 20.6296 - val_loss: 83.5634\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 19.9251 - val_loss: 80.9350\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 19.2362 - val_loss: 78.4753\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 18.5788 - val_loss: 76.1025\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 17.9523 - val_loss: 73.7612\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 17.3381 - val_loss: 71.4411\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 16.7472 - val_loss: 69.1260\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 16.1799 - val_loss: 66.7955\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.5876 - val_loss: 64.6859\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.0473 - val_loss: 62.5617\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 14.4609 - val_loss: 60.8732\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 13.9902 - val_loss: 58.8456\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 13.5050 - val_loss: 56.7667\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.9712 - val_loss: 55.0322\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 875us/sample - loss: 12.5151 - val_loss: 53.2554\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.0640 - val_loss: 51.4380\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 11.6356 - val_loss: 49.5597\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 11.1838 - val_loss: 47.8622\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 3ms/sample - loss: 10.7457 - val_loss: 46.3198\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.3428 - val_loss: 44.8073\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 3ms/sample - loss: 9.9688 - val_loss: 43.2165\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.5609 - val_loss: 41.8932\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.2151 - val_loss: 40.4488\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.8619 - val_loss: 38.9853\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.5154 - val_loss: 37.5823\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.1780 - val_loss: 36.2470\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.8610 - val_loss: 34.9301\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.5407 - val_loss: 33.7111\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.2286 - val_loss: 32.6088\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.9580 - val_loss: 31.3972\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.6594 - val_loss: 30.3733\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.4314 - val_loss: 29.1137\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.1277 - val_loss: 28.1348\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.8860 - val_loss: 27.1279\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.6748 - val_loss: 26.0003\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.4036 - val_loss: 25.0967\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.1683 - val_loss: 24.3146\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.9637 - val_loss: 23.4988\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.7708 - val_loss: 22.5424\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.5556 - val_loss: 21.7237\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.3659 - val_loss: 20.9069\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.1970 - val_loss: 20.0129\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.0032 - val_loss: 19.2387\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.8235 - val_loss: 18.5420\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.6586 - val_loss: 17.8724\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.4992 - val_loss: 17.2371\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.3578 - val_loss: 16.5417\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.2151 - val_loss: 15.8590\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.0733 - val_loss: 15.2227\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.9239 - val_loss: 14.7000\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.8014 - val_loss: 14.1616\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.6792 - val_loss: 13.6255\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.5632 - val_loss: 13.0902\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.4535 - val_loss: 12.5618\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.3364 - val_loss: 12.1200\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.2361 - val_loss: 11.6672\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.1423 - val_loss: 11.1893\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.0499 - val_loss: 10.7186\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.9537 - val_loss: 10.3069\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.8631 - val_loss: 9.9527\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.7936 - val_loss: 9.5255\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.7076 - val_loss: 9.1559\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.6350 - val_loss: 8.7857\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.5632 - val_loss: 8.4374\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.4897 - val_loss: 8.1718\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.4343 - val_loss: 7.8188\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.3682 - val_loss: 7.5134\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.3081 - val_loss: 7.2350\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2546 - val_loss: 6.9477\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2006 - val_loss: 6.6813\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.1532 - val_loss: 6.4044\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.1030 - val_loss: 6.1607\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.0609 - val_loss: 5.9033\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.0152 - val_loss: 5.6759\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.9725 - val_loss: 5.4746\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.9356 - val_loss: 5.2682\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.9022 - val_loss: 5.0489\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.8646 - val_loss: 4.8628\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.8318 - val_loss: 4.6851\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.7998 - val_loss: 4.5378\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.7745 - val_loss: 4.3476\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.7476 - val_loss: 4.1657\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.7167 - val_loss: 4.0306\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6940 - val_loss: 3.8802\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6704 - val_loss: 3.7395\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6483 - val_loss: 3.6113\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6299 - val_loss: 3.4652\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6079 - val_loss: 3.3462\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5911 - val_loss: 3.2177\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5726 - val_loss: 3.1050\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5558 - val_loss: 3.0051\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5405 - val_loss: 2.9114\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5287 - val_loss: 2.7947\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5132 - val_loss: 2.7011\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5000 - val_loss: 2.6229\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4886 - val_loss: 2.5360\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4778 - val_loss: 2.4463\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4679 - val_loss: 2.3570\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4564 - val_loss: 2.3002\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4480 - val_loss: 2.2194\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4394 - val_loss: 2.1419\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4303 - val_loss: 2.0820\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4227 - val_loss: 2.0248\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4160 - val_loss: 1.9642\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4096 - val_loss: 1.8960\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4035 - val_loss: 1.8321\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3968 - val_loss: 1.7834\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3910 - val_loss: 1.7394\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3862 - val_loss: 1.6944\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3821 - val_loss: 1.6379\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3772 - val_loss: 1.5880\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3724 - val_loss: 1.5503\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3683 - val_loss: 1.5118\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3652 - val_loss: 1.4691\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3610 - val_loss: 1.4403\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3577 - val_loss: 1.4147\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3548 - val_loss: 1.3782\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3527 - val_loss: 1.3375\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3491 - val_loss: 1.3073\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3463 - val_loss: 1.2820\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3441 - val_loss: 1.2506\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3414 - val_loss: 1.2298\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3403 - val_loss: 1.1947\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3372 - val_loss: 1.1760\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3352 - val_loss: 1.1573\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3335 - val_loss: 1.1338\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3319 - val_loss: 1.1065\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3299 - val_loss: 1.0919\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3284 - val_loss: 1.0698\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3267 - val_loss: 1.0519\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3251 - val_loss: 1.0361\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3237 - val_loss: 1.0170\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3224 - val_loss: 1.0023\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3210 - val_loss: 0.9902\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3199 - val_loss: 0.9695\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3187 - val_loss: 0.9514\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3172 - val_loss: 0.9411\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3162 - val_loss: 0.9267\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3150 - val_loss: 0.9112\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3138 - val_loss: 0.8988\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3126 - val_loss: 0.8893\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3118 - val_loss: 0.8762\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3104 - val_loss: 0.8684\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3095 - val_loss: 0.8603\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3084 - val_loss: 0.8553\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3074 - val_loss: 0.8489\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3065 - val_loss: 0.8406\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3057 - val_loss: 0.8248\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3044 - val_loss: 0.8209\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3044 - val_loss: 0.8016\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3025 - val_loss: 0.7968\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3021 - val_loss: 0.8075\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3007 - val_loss: 0.7896\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2996 - val_loss: 0.7856\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2987 - val_loss: 0.7820\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2978 - val_loss: 0.7682\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2967 - val_loss: 0.7629\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2958 - val_loss: 0.7531\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2949 - val_loss: 0.7558\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2938 - val_loss: 0.7460\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2933 - val_loss: 0.7359\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2918 - val_loss: 0.7375\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2909 - val_loss: 0.7296\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2901 - val_loss: 0.7295\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2891 - val_loss: 0.7286\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2881 - val_loss: 0.7256\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2871 - val_loss: 0.7114\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2861 - val_loss: 0.7029\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2850 - val_loss: 0.7011\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2844 - val_loss: 0.7031\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2837 - val_loss: 0.7040\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2820 - val_loss: 0.6946\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2813 - val_loss: 0.6915\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2802 - val_loss: 0.6822\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2796 - val_loss: 0.6869\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2782 - val_loss: 0.6793\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2777 - val_loss: 0.6700\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2765 - val_loss: 0.6720\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2763 - val_loss: 0.6557\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2743 - val_loss: 0.6550\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2734 - val_loss: 0.6542\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2724 - val_loss: 0.6593\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2719 - val_loss: 0.6444\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2709 - val_loss: 0.6591\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2691 - val_loss: 0.6524\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2683 - val_loss: 0.6491\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2675 - val_loss: 0.6465\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2663 - val_loss: 0.6350\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2652 - val_loss: 0.6405\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2642 - val_loss: 0.6317\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2630 - val_loss: 0.6283\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2619 - val_loss: 0.6250\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2609 - val_loss: 0.6203\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2598 - val_loss: 0.6215\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2589 - val_loss: 0.6142\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2578 - val_loss: 0.6175\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2566 - val_loss: 0.6122\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2558 - val_loss: 0.6169\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2545 - val_loss: 0.6058\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2534 - val_loss: 0.6046\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2524 - val_loss: 0.5976\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2513 - val_loss: 0.5936\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2502 - val_loss: 0.5926\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2492 - val_loss: 0.5890\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2487 - val_loss: 0.5990\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2468 - val_loss: 0.5935\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2458 - val_loss: 0.5829\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2451 - val_loss: 0.5838\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2437 - val_loss: 0.5729\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2427 - val_loss: 0.5661\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2414 - val_loss: 0.5700\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2403 - val_loss: 0.5699\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2392 - val_loss: 0.5673\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2382 - val_loss: 0.5658\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2370 - val_loss: 0.5615\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2358 - val_loss: 0.5554\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2348 - val_loss: 0.5538\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2339 - val_loss: 0.5519\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2325 - val_loss: 0.5525\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2313 - val_loss: 0.5523\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2303 - val_loss: 0.5474\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2292 - val_loss: 0.5431\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2279 - val_loss: 0.5444\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2267 - val_loss: 0.5383\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2257 - val_loss: 0.5400\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2247 - val_loss: 0.5240\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2233 - val_loss: 0.5211\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2223 - val_loss: 0.5178\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2210 - val_loss: 0.5229\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15,16,17,18,19,20])\n",
    "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model2 = Sequential()\n",
    "\n",
    "# Single-Layer Perceptron\n",
    "# output node: 1\n",
    "# num of input: 1\n",
    "# activation function: linear\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "# output node: 10\n",
    "# num of input: 1\n",
    "# activation function: linear\n",
    "model2.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Setting Model\n",
    "# back propagation: adam\n",
    "# loss algorithm: mse\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Start Learning \n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True, epochs=300, batch_size=1)\n",
    "# x_train: data\n",
    "# y_train: target \n",
    "# validation_split=0.2: (0.8 => learning data, 0.2=> validation data)\n",
    "# shuffle=True (use randomized validation)\n",
    "# epochs=300 \n",
    "# batch_size=1 (update when 1 data learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 20ms/sample - loss: 185.3542 - val_loss: 646.0731\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 166.3204 - val_loss: 576.6564\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 147.2544 - val_loss: 515.0201\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 131.1771 - val_loss: 450.9445\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 114.1548 - val_loss: 394.9921\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 98.2533 - val_loss: 344.5211\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 85.0827 - val_loss: 291.4297\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 71.5200 - val_loss: 243.4227\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 59.5163 - val_loss: 199.6899\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 47.4368 - val_loss: 165.5037\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 37.9501 - val_loss: 133.9571\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 29.9420 - val_loss: 104.4536\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 22.6852 - val_loss: 80.6465\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 17.0194 - val_loss: 60.2190\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 12.2618 - val_loss: 44.6069\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 23.34 - 0s 2ms/sample - loss: 8.9206 - val_loss: 31.5084\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.9086 - val_loss: 23.1277\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.0125 - val_loss: 17.0669\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.8347 - val_loss: 11.4458\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.7877 - val_loss: 8.1478\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2554 - val_loss: 5.4717\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.8182 - val_loss: 3.9544\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6123 - val_loss: 2.7752\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4522 - val_loss: 2.1276\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3741 - val_loss: 1.6746\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3400 - val_loss: 1.2617\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3094 - val_loss: 1.0299\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2880 - val_loss: 0.9833\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2870 - val_loss: 0.8087\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2750 - val_loss: 0.7569\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2714 - val_loss: 0.7009\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2683 - val_loss: 0.7165\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2655 - val_loss: 0.6491\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2626 - val_loss: 0.6291\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2606 - val_loss: 0.5950\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2589 - val_loss: 0.6258\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2561 - val_loss: 0.5823\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2520 - val_loss: 0.5724\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2495 - val_loss: 0.5892\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2471 - val_loss: 0.5844\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2450 - val_loss: 0.5656\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2428 - val_loss: 0.5851\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2392 - val_loss: 0.5587\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2373 - val_loss: 0.5309\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2353 - val_loss: 0.5010\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2318 - val_loss: 0.5193\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2290 - val_loss: 0.5162\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2260 - val_loss: 0.5076\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2233 - val_loss: 0.4943\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2214 - val_loss: 0.4897\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2194 - val_loss: 0.5265\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2174 - val_loss: 0.5477\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2135 - val_loss: 0.4697\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2114 - val_loss: 0.4922\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2076 - val_loss: 0.4463\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2053 - val_loss: 0.4802\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2017 - val_loss: 0.4636\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1993 - val_loss: 0.4256\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1971 - val_loss: 0.4138\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1941 - val_loss: 0.4348\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1929 - val_loss: 0.4760\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1883 - val_loss: 0.4177\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1864 - val_loss: 0.3872\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1827 - val_loss: 0.4118\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1812 - val_loss: 0.4223\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1779 - val_loss: 0.3912\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1749 - val_loss: 0.3803\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1717 - val_loss: 0.3952\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1700 - val_loss: 0.3917\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1670 - val_loss: 0.4041\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1651 - val_loss: 0.3678\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1629 - val_loss: 0.3431\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1610 - val_loss: 0.3941\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1565 - val_loss: 0.3748\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1544 - val_loss: 0.3329\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1530 - val_loss: 0.3099\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1483 - val_loss: 0.3441\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1490 - val_loss: 0.3918\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1439 - val_loss: 0.3229\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1417 - val_loss: 0.3018\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1395 - val_loss: 0.3286\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1363 - val_loss: 0.2996\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1339 - val_loss: 0.3068\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1313 - val_loss: 0.2923\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1296 - val_loss: 0.2837\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1274 - val_loss: 0.2591\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1243 - val_loss: 0.2592\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1215 - val_loss: 0.2778\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1198 - val_loss: 0.2846\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1173 - val_loss: 0.2725\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1169 - val_loss: 0.2427\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1129 - val_loss: 0.2349\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1109 - val_loss: 0.2623\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1086 - val_loss: 0.2342\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1055 - val_loss: 0.2341\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1035 - val_loss: 0.2440\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1015 - val_loss: 0.2216\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0997 - val_loss: 0.2367\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0974 - val_loss: 0.2180\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0949 - val_loss: 0.2193\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0929 - val_loss: 0.2130\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0912 - val_loss: 0.1908\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0894 - val_loss: 0.2123\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0866 - val_loss: 0.1949\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0854 - val_loss: 0.1887\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0829 - val_loss: 0.1814\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0811 - val_loss: 0.1759\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0799 - val_loss: 0.1840\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0775 - val_loss: 0.1656\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0761 - val_loss: 0.1573\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0741 - val_loss: 0.1676\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0718 - val_loss: 0.1617\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0706 - val_loss: 0.1434\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0684 - val_loss: 0.1441\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0676 - val_loss: 0.1722\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0662 - val_loss: 0.1346\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0636 - val_loss: 0.1316\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0632 - val_loss: 0.1520\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0609 - val_loss: 0.1160\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0585 - val_loss: 0.1215\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0573 - val_loss: 0.1400\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0564 - val_loss: 0.1107\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0539 - val_loss: 0.1256\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0526 - val_loss: 0.1157\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0515 - val_loss: 0.1276\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0496 - val_loss: 0.1145\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0484 - val_loss: 0.1054\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0469 - val_loss: 0.0948\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0458 - val_loss: 0.1011\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0446 - val_loss: 0.0862\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0428 - val_loss: 0.0942\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0418 - val_loss: 0.1031\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0417 - val_loss: 0.0810\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0393 - val_loss: 0.0858\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0378 - val_loss: 0.0883\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0378 - val_loss: 0.0930\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0363 - val_loss: 0.0888\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0342 - val_loss: 0.0682\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0336 - val_loss: 0.0668\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0326 - val_loss: 0.0616\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0322 - val_loss: 0.0718\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0310 - val_loss: 0.0674\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0300 - val_loss: 0.0711\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0286 - val_loss: 0.0568\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0285 - val_loss: 0.0440\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0271 - val_loss: 0.0689\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0260 - val_loss: 0.0521\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0258 - val_loss: 0.0628\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0244 - val_loss: 0.0417\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0232 - val_loss: 0.0470\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0225 - val_loss: 0.0517\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0217 - val_loss: 0.0418\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0207 - val_loss: 0.0490\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0201 - val_loss: 0.0476\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0195 - val_loss: 0.0448\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0188 - val_loss: 0.0366\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0180 - val_loss: 0.0366\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0174 - val_loss: 0.0399\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0169 - val_loss: 0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0159 - val_loss: 0.0331\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0159 - val_loss: 0.0415\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0146 - val_loss: 0.0282\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0142 - val_loss: 0.0282\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0137 - val_loss: 0.0292\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0131 - val_loss: 0.0281\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0126 - val_loss: 0.0248\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0122 - val_loss: 0.0272\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0118 - val_loss: 0.0214\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0113 - val_loss: 0.0281\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0107 - val_loss: 0.0202\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0102 - val_loss: 0.0197\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0098 - val_loss: 0.0212\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0093 - val_loss: 0.0191\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0089 - val_loss: 0.0181\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0086 - val_loss: 0.0203\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0081 - val_loss: 0.0175\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0078 - val_loss: 0.0154\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0075 - val_loss: 0.0164\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0071 - val_loss: 0.0164\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0068 - val_loss: 0.0139\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0065 - val_loss: 0.0122\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0062 - val_loss: 0.0122\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0059 - val_loss: 0.0135\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0057 - val_loss: 0.0121\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0047 - val_loss: 0.0094\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0044 - val_loss: 0.0104\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0042 - val_loss: 0.0084\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0039 - val_loss: 0.0102\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0033 - val_loss: 0.0087\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.9421e-04 - val_loss: 0.0019\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.3585e-04 - val_loss: 0.0017\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.9590e-04 - val_loss: 0.0022\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.2708e-04 - val_loss: 0.0015\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.7037e-04 - val_loss: 0.0015\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.3110e-04 - val_loss: 0.0017\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.8125e-04 - val_loss: 0.0015\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.4864e-04 - val_loss: 0.0012\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.8347e-04 - val_loss: 0.0013\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.5086e-04 - val_loss: 0.0013\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.2358e-04 - val_loss: 0.0013\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.8336e-04 - val_loss: 0.0010\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.4884e-04 - val_loss: 0.0011\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.2635e-04 - val_loss: 7.2071e-04\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.9041e-04 - val_loss: 9.6766e-04\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.6558e-04 - val_loss: 8.0473e-04\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.3541e-04 - val_loss: 5.7316e-04\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.1301e-04 - val_loss: 6.8957e-04\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.9355e-04 - val_loss: 7.4406e-04\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.8082e-04 - val_loss: 3.8782e-04\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.6208e-04 - val_loss: 6.9019e-04\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.3625e-04 - val_loss: 4.8133e-04\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.1479e-04 - val_loss: 3.5291e-04\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.0565e-04 - val_loss: 4.1262e-04\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.8994e-04 - val_loss: 4.5700e-04\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.8437e-04 - val_loss: 1.8270e-04\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.5894e-04 - val_loss: 4.2913e-04\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.4442e-04 - val_loss: 3.0195e-04\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.3768e-04 - val_loss: 1.9491e-04\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2660e-04 - val_loss: 3.7314e-04\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.1427e-04 - val_loss: 2.5145e-04\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.0230e-04 - val_loss: 1.8462e-04\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.5941e-05 - val_loss: 1.7355e-04\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.4658e-05 - val_loss: 1.7841e-04\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.0178e-05 - val_loss: 1.2545e-04\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.6801e-05 - val_loss: 1.5858e-04\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.8815e-05 - val_loss: 9.7004e-05\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.4622e-05 - val_loss: 1.5388e-04\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.7991e-05 - val_loss: 7.9824e-05\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.3814e-05 - val_loss: 1.3902e-04\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.2981e-05 - val_loss: 6.2218e-05\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.2399e-05 - val_loss: 1.1146e-04\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.1211e-05 - val_loss: 7.8224e-05\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.5777e-05 - val_loss: 7.0987e-05\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.3531e-05 - val_loss: 6.8136e-05\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.0732e-05 - val_loss: 4.5720e-05\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.6746e-05 - val_loss: 7.5015e-05\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.5492e-05 - val_loss: 4.6002e-05\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.2953e-05 - val_loss: 4.7919e-05\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.0907e-05 - val_loss: 3.4868e-05\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.8616e-05 - val_loss: 4.2891e-05\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.7303e-05 - val_loss: 3.9763e-05\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.5489e-05 - val_loss: 2.7624e-05\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.4880e-05 - val_loss: 4.1416e-05\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2317e-05 - val_loss: 1.7279e-05\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.1585e-05 - val_loss: 2.4313e-05\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.0252e-05 - val_loss: 2.4133e-05\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.5499e-06 - val_loss: 1.9523e-05\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.3895e-06 - val_loss: 1.7965e-05\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.5862e-06 - val_loss: 1.1755e-05\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.7577e-06 - val_loss: 1.4171e-05\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 6.3170e-06 - val_loss: 1.0127e-05\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.7915e-06 - val_loss: 1.7494e-05\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.9256e-06 - val_loss: 6.6121e-06\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.5023e-06 - val_loss: 7.9167e-06\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.1987e-06 - val_loss: 1.4344e-05\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.7223e-06 - val_loss: 6.1156e-06\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.2458e-06 - val_loss: 4.3743e-06\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.8192e-06 - val_loss: 5.6897e-06\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.5068e-06 - val_loss: 5.6378e-06\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.3275e-06 - val_loss: 4.4925e-06\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.9858e-06 - val_loss: 4.5990e-06\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.7141e-06 - val_loss: 2.3488e-06\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.6388e-06 - val_loss: 3.4032e-06\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.4178e-06 - val_loss: 2.2423e-06\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.2718e-06 - val_loss: 1.9176e-06\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.1663e-06 - val_loss: 3.3664e-06\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 9.6090e-07 - val_loss: 9.3765e-07\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.3905e-07 - val_loss: 2.2455e-06\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.7756e-07 - val_loss: 1.7713e-06\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 7.0019e-07 - val_loss: 1.1426e-06\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.9138e-07 - val_loss: 1.1821e-06\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.5166e-07 - val_loss: 1.2320e-06\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.5469e-07 - val_loss: 6.4476e-07\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 4.0276e-07 - val_loss: 1.2016e-06\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.4843e-07 - val_loss: 4.6069e-07\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_train, y_train, validation_split=0.2, shuffle=True, epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chart Model Result\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "# set y-axis\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 3537.0]) \n",
    "\n",
    "# set labels\n",
    "loss_ax.set_xlabel('epoch')  \n",
    "loss_ax.set_ylabel('loss')   \n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chart Model Result\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "# set y-axis\n",
    "loss_ax.plot(hist2.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist2.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "# set labels\n",
    "loss_ax.set_xlabel('epoch')  \n",
    "loss_ax.set_ylabel('loss')   \n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[ 98.29951]\n",
      " [100.20767]\n",
      " [102.11584]\n",
      " [104.024  ]\n",
      " [105.93216]]\n",
      "x: 51, actual: 102, predicted: 98.29951\n",
      "x: 52, actual: 104, predicted: 100.20767\n",
      "x: 53, actual: 106, predicted: 102.11584\n",
      "x: 54, actual: 108, predicted: 104.02400\n",
      "x: 55, actual: 110, predicted: 105.93216\n"
     ]
    }
   ],
   "source": [
    "x = np.array([51, 52, 53, 54, 55])\n",
    "y = np.array([102, 104, 106, 108, 110])\n",
    "\n",
    "pd = model.predict(x) \n",
    "print(pd.shape)\n",
    "print(pd)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, actual: {1}, predicted: {2:.5f}'\n",
    "    print(fmt.format(x[i], y[i], pd[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[101.99607 ]\n",
      " [103.99597 ]\n",
      " [105.995865]\n",
      " [107.99577 ]\n",
      " [109.99568 ]]\n",
      "x: 51, actual: 102, predicted: 101.99607\n",
      "x: 52, actual: 104, predicted: 103.99597\n",
      "x: 53, actual: 106, predicted: 105.99586\n",
      "x: 54, actual: 108, predicted: 107.99577\n",
      "x: 55, actual: 110, predicted: 109.99568\n"
     ]
    }
   ],
   "source": [
    "pd2 = model2.predict(x) \n",
    "print(pd2.shape)\n",
    "print(pd2)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, actual: {1}, predicted: {2:.5f}'\n",
    "    print(fmt.format(x[i], y[i], pd2[i][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
